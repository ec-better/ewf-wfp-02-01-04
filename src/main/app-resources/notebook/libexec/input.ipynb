{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ewf-wfp-02-01-04 - Land Surface Temperature Anomalies Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Land Surface Temperature Anomalies Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"service\">Service definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "service = dict([('title', 'Land Surface Temperature Anomalies Time Series'),\n",
    "                ('abstract', 'Land Surface Temperature Anomalies Time Series'),\n",
    "                ('id', 'ewf-wfp-02-01-04')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"parameter\">Parameter Definition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_1 = dict([('id', 'N_1'),\n",
    "                          ('value', 'False'),\n",
    "                          ('title', 'No Aggregation'),\n",
    "                          ('abstract', 'No aggregation')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_3 = dict([('id', 'N_3'),\n",
    "                          ('value', 'True'),\n",
    "                          ('title', '30 Day Aggregation'),\n",
    "                          ('abstract', 'Get a 30 day aggregation')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_6 = dict([('id', 'N_6'),\n",
    "                          ('value', 'False'),\n",
    "                          ('title', '60 Day Aggregation'),\n",
    "                          ('abstract', 'Get a 30 day aggregation')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " N_9 = dict([('id', 'N_9'),\n",
    "                          ('value', 'False'),\n",
    "                          ('title', '90 Day Aggregation'),\n",
    "                          ('abstract', 'Get a 90 day aggregation')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " N_12 = dict([('id', 'N_12'),\n",
    "                          ('value', 'False'),\n",
    "                          ('title', '120 Day Aggregation'),\n",
    "                          ('abstract', 'Get a 120 day aggregation')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    " N_15 = dict([('id', 'N_15'),\n",
    "                          ('value', 'False'),\n",
    "                          ('title', '150 Day Aggregation'),\n",
    "                          ('abstract', 'Get a 150 day aggregation')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    " N_18 = dict([('id', 'N_18'),\n",
    "                          ('value', 'False'),\n",
    "                          ('title', '180 Day Aggregation'),\n",
    "                          ('abstract', 'Get a 180 day aggregation')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    " N_27 = dict([('id', 'N_27'),\n",
    "                          ('value', 'False'),\n",
    "                          ('title', '270 Day Aggregation'),\n",
    "                          ('abstract', 'Get a 270 day aggregation')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    " N_36 = dict([('id', 'N_36'),\n",
    "                          ('value', 'False'),\n",
    "                          ('title', '360 Day Aggregation'),\n",
    "                          ('abstract', 'Get a 360 day aggregation')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "regionOfInterest = dict([('id', 'regionOfInterest'),\n",
    "                         ('value', 'POLYGON((11.5030755518998 -11.1141633706909,41.0343255518998 -11.1141633706909,41.0343255518998 -34.9763656693858,11.5030755518998 -34.9763656693858,11.5030755518998 -11.1141633706909))'),\n",
    "                         ('title', 'WKT Polygon for the Region of Interest'),\n",
    "                         ('abstract', 'Set the value of WKT Polygon')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nameOfRegion = dict([('id', 'nameOfRegion'),\n",
    "                     ('value', 'SouthernAfrica'),\n",
    "                     ('title', 'Name of Region'),\n",
    "                     ('abstract', 'Name of the region of interest'),\n",
    "                     ('minOccurs', '1')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"runtime\">Runtime parameter definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input identifiers**\n",
    "\n",
    "This is the MDOIS stack of products' identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2015, 2016, 2017\n",
    "input_identifiers = ('LST_SouthernAfrica_N3_averages_2015-01-05_2015-01-25.tif', 'LTA_LST_SouthernAfrica_N3_averages_1-5_1-25_2015_2017.tif')\n",
    "\n",
    "#, 'LST_SouthernAfrica_N3_maxvalues_2015-01-01_2015-01-21.tif', 'LST_SouthernAfrica_N3_maxvalues_2016-01-01_2016-01-21.tif', 'LST_SouthernAfrica_N3_maxvalues_2017-01-01_2017-01-21.tif'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input references**\n",
    "\n",
    "This is the MODIS stack catalogue references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "input_references = ('https://catalog.terradue.com/modis/search?uid=MOD11C2.A2017001.006.2017013160908', 'https://catalog.terradue.com/modis/search?uid=MOD11C2.A2017009.006.2017020191355', 'https://catalog.terradue.com/modis/search?uid=MOD11C2.A2017017.006.2017025093208') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Data path**\n",
    "\n",
    "This path defines where the data is staged-in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"/workspace/modis/outputs/output_02_03\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aux folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_folder = 'temp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import sys\n",
    "import string\n",
    "import numpy as np\n",
    "from osgeo import gdal, ogr, osr\n",
    "from shapely.wkt import loads\n",
    "\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_results = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_cfolder(folder):\n",
    "    #folder = '/path/to/folder'\n",
    "    for the_file in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, the_file)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path): shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print(e) \n",
    "    \n",
    "def get_metadata(filepath):\n",
    "        \n",
    "    #pdb.set_trace()\n",
    "    ds = gdal.Open(filepath)\n",
    "    projection = ds.GetProjection()\n",
    "    geotransform = ds.GetGeoTransform()\n",
    "    no_data_value = ds.GetRasterBand(1).GetNoDataValue()\n",
    "    data_type = ds.GetRasterBand(1).DataType\n",
    "    return projection, geotransform, no_data_value, data_type\n",
    "\n",
    "\n",
    "def get_matrix_list(image_list):\n",
    "    mat_list = []\n",
    "    for img in image_list:\n",
    "        dataset = gdal.Open(img)\n",
    "        product_array = dataset.GetRasterBand(1).ReadAsArray()\n",
    "        mat_list.append(product_array)\n",
    "        dataset = None\n",
    "        \n",
    "        print(type(product_array))\n",
    "    return mat_list\n",
    "\n",
    "\n",
    "def calc_anomaly(agg_file, LTA_file):\n",
    "    \n",
    "    \n",
    "    #file_list = []\n",
    "    #if not os.path.isdir('tmp_data'):\n",
    "    #    os.mkdir('tmp_data')\n",
    "    #for enclosure in dataframe['enclosure'].tolist():\n",
    "    #    filepath = 'tmp_data/' + os.path.basename(enclosure)\n",
    "    #    status = get_product(enclosure, filepath)\n",
    "    #    if status == 200:\n",
    "    #        file_list.append(filepath)\n",
    "    #print(file_list)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if agg_file and LTA_file:\n",
    "        \n",
    "        \n",
    "        agg_and_LTA = get_matrix_list([agg_file, LTA_file])\n",
    "        print('Aggregation and LTA converted to matrices')\n",
    "        \n",
    "        print(agg_and_LTA[0].dtype)\n",
    "        print(agg_and_LTA[1].dtype)\n",
    "        \n",
    "        #anomaly_values = np.divide(agg_and_LTA[0] * 1.0, agg_and_LTA[1] * 1.0)\n",
    "        \n",
    "        anomaly_values = np.divide(agg_and_LTA[0] * 1.0, agg_and_LTA[1] * 1.0, out=np.zeros_like(agg_and_LTA[0] * 1.0), where=agg_and_LTA[1]!=0)\n",
    "        \n",
    "        #anomaly_values[(agg_and_LTA[0] == 0)] = 0\n",
    "        #anomaly_values[(agg_and_LTA[1] == 0)] = 0\n",
    "        \n",
    "        print(anomaly_values.dtype)\n",
    "        \n",
    "        projection, geotransform, no_data_value, data_type = get_metadata(agg_file)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #for file_ in file_list:\n",
    "        #    os.remove(file_)\n",
    "        \n",
    "        return anomaly_values, projection, geotransform, no_data_value, data_type\n",
    "    \n",
    "    else:\n",
    "        return None, None, None\n",
    "\n",
    "\n",
    "def write_output_image(filepath, output_matrix, image_format, data_format, mask=None, output_projection=None, output_geotransform=None, no_data_value=None):\n",
    "    driver = gdal.GetDriverByName(image_format)\n",
    "    out_rows = np.size(output_matrix, 0)\n",
    "    out_columns = np.size(output_matrix, 1)\n",
    "    if mask is not None and mask is not 0:\n",
    "        output = driver.Create(filepath, out_columns, out_rows, 2, data_format)\n",
    "        mask_band = output.GetRasterBand(2)\n",
    "        mask_band.WriteArray(mask)\n",
    "        if no_data_value is not None:\n",
    "            output_matrix[mask > 0] = no_data_value\n",
    "    else:\n",
    "        output = driver.Create(filepath, out_columns, out_rows, 1, data_format)\n",
    "    \n",
    "    if output_projection is not None:\n",
    "        output.SetProjection(output_projection)\n",
    "    if output_geotransform is not None:\n",
    "        output.SetGeoTransform(output_geotransform)\n",
    "    \n",
    "    raster_band = output.GetRasterBand(1)\n",
    "    if no_data_value is not None:\n",
    "        raster_band.SetNoDataValue(no_data_value)\n",
    "    raster_band.WriteArray(output_matrix)\n",
    "    gdal.Warp(filepath, output, format=\"GTiff\", outputBoundsSRS='EPSG:4326', xRes=output_geotransform[1], yRes=-output_geotransform[5], targetAlignedPixels=True)\n",
    "\n",
    "    \n",
    "\n",
    "def write_anomaly_output(anomaly, output_folder, product_name, first_date, last_date, lta_start_year, lta_end_year, aggregation, mask_no_value, N_value, regionOfInterest, roi_name, projection, geo_transform, no_data_value):\n",
    "    #image_number = (datetime.strptime(last_date, '%Y-%m-%d') - datetime.strptime(first_date, '%Y-%m-%d')).days\n",
    "    \n",
    "    \n",
    "    #filename =  output_folder + '/' + product_name + '_Anomaly_' + roi_name + '_N' + str(N_value) + '_' + aggregation + '_' + first_date + '_' + last_date + '_LTA' + str(lta_start_year) + '_' + str(lta_end_year) + '.tif'\n",
    "    \n",
    "    filename = os.path.join(output_folder, product_name + '_Anomaly_' + roi_name + '_N' + str(N_value) + '_' + aggregation + '_' + first_date + '_' + last_date + '_LTA' + str(lta_start_year) + '_' + str(lta_end_year) + '.tif')\n",
    "    \n",
    "    write_output_image(filename, anomaly, 'GTiff', gdal.GDT_Float32, mask_no_value, projection, geo_transform, no_data_value)\n",
    "    return filename\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create folders\n",
    "#if not os.path.isdir(data_path):\n",
    "#    os.mkdir(data_path)\n",
    "\n",
    "if len(output_folder) > 0:\n",
    "    if not os.path.isdir(output_folder):\n",
    "        os.mkdir(output_folder)\n",
    "\n",
    "if not os.path.isdir(temp_folder):\n",
    "    os.mkdir(temp_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/modis/outputs/output_02_03/LST_SouthernAfrica_N3_averages_2015-01-05_2015-01-25.tif\n",
      "/workspace/modis/outputs/output_02_03/LTA_LST_SouthernAfrica_N3_averages_1-5_1-25_2015_2017.tif\n",
      "/workspace/modis/outputs/output_02_03/LST_SouthernAfrica_N3_averages_2015-01-05_2015-01-25.tif\n",
      "/workspace/modis/outputs/output_02_03/LTA_LST_SouthernAfrica_N3_averages_1-5_1-25_2015_2017.tif\n",
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n",
      "Aggregation and LTA converted to matrices\n",
      "uint16\n",
      "uint16\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "#print('hello')\n",
    "#pdb.set_trace()\n",
    "if isinstance(input_identifiers, str):\n",
    "    input_identifiers = [input_identifiers]\n",
    "\n",
    "region_of_interest = regionOfInterest['value']\n",
    "name_of_region = nameOfRegion['value']\n",
    "\n",
    "filepath_agg = os.path.join(data_path, input_identifiers[0].split('/')[-1])\n",
    "filepath_LTA = os.path.join(data_path, input_identifiers[1].split('/')[-1])\n",
    "\n",
    "#filepath_agg = data_path + '/' + input_identifiers[0]\n",
    "#filepath_LTA = data_path + '/' + input_identifiers[1]\n",
    "\n",
    "# N time steps\n",
    "nlist = [N_1['value'], N_3['value'], N_6['value']]\n",
    "nlist = [n == 'True' for n in nlist]\n",
    "nvalues = [1, 3, 6]\n",
    "\n",
    "# list of files\n",
    "\n",
    "print(filepath_agg)\n",
    "print(filepath_LTA)\n",
    "\n",
    "# get metadata from filenames\n",
    "\n",
    "file_name_elements = os.path.basename(filepath_agg).split('.')[0].split('_')\n",
    "#['LST', 'SouthernAfrica', 'N3', 'averages', '2015-01-01', '2015-01-21']\n",
    "first_date = file_name_elements[-2]\n",
    "last_date = file_name_elements[-1]\n",
    "agg_type = file_name_elements[-3]\n",
    "Nn = file_name_elements[-4]\n",
    "\n",
    "\n",
    "file_name_elements = os.path.basename(filepath_LTA).split('.')[0].split('_')\n",
    "#['LTA', 'LST', 'SouthernAfrica', 'N3', 'averages', '1-1', '1-21', '2015', '2017']\n",
    "\n",
    "start_year = file_name_elements[-2]\n",
    "end_year = file_name_elements[-1]\n",
    "\n",
    "agg_type_LTA = file_name_elements[-5]\n",
    "Nn_LTA = file_name_elements[-6]\n",
    "\n",
    "\n",
    "\n",
    "# do some checks TODO\n",
    "pass\n",
    "\n",
    "for bl,nv in zip(nlist, nvalues):\n",
    "    \n",
    "    # only works for selected N time steps\n",
    "    if bl:        \n",
    "\n",
    "            #filename = os.path.splitext(os.path.basename(file_list[0]))[0].split('_')\n",
    "            #agr = filename[3]\n",
    "            #prod_type = filename[0]\n",
    "            #N_value = filename[2]\n",
    "            #region = filename[1]\n",
    "\n",
    "        \n",
    "            #agg_values = get_matrix_list(agg_file)[0]\n",
    "        \n",
    "            print(filepath_agg)\n",
    "            print(filepath_LTA)\n",
    "        \n",
    "            anomaly_values, projection, geotransform, no_data_value, data_type = calc_anomaly(filepath_agg, filepath_LTA)\n",
    "        \n",
    "            filename = write_anomaly_output(anomaly_values, output_folder, 'LST', first_date, last_date, start_year, end_year, agg_type, None, nv, region_of_interest, name_of_region, projection, geotransform, no_data_value)\n",
    "            \n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_results:\n",
    "\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(anomaly_values)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_results:\n",
    "\n",
    "    import rasterio\n",
    "\n",
    "    from rasterio.plot import show\n",
    "\n",
    "    # Load data\n",
    "    #raster = output_folder + '/' + 'LST_Anomaly_SouthernAfrica_N3_averages_2015-01-01_2015-01-21_LTA2015_2017.tif'\n",
    "    raster = filename\n",
    "    data = rasterio.open(raster)\n",
    "\n",
    "    show(data)\n",
    "\n",
    "    #data = georasters.from_file(raster)\n",
    "\n",
    "    # Plot data\n",
    "    #data.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove temporay files and folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_cfolder(temp_folder)\n",
    "\n",
    "os.rmdir(temp_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vacc-env2",
   "language": "python",
   "name": "vacc-env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
