{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ewf-wfp-02-01-04 - Land Surface Temperature Anomalies Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Land Surface Temperature Anomalies Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"service\">Service definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "service = dict([('title', 'Land Surface Temperature Anomalies Time Series'),\n",
    "                ('abstract', 'Land Surface Temperature Anomalies Time Series'),\n",
    "                ('id', 'ewf-wfp-02-01-04')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"parameter\">Parameter Definition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_1 = dict([('id', 'N_1'),\n",
    "            ('value', 'False'),\n",
    "            ('title', 'No Aggregation'),\n",
    "            ('abstract', 'No aggregation')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_3 = dict([('id', 'N_3'),\n",
    "            ('value', 'True'),\n",
    "            ('title', '30 Day Aggregation'),\n",
    "            ('abstract', 'Get a 30 day aggregation')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_6 = dict([('id', 'N_6'),\n",
    "            ('value', 'True'),\n",
    "            ('title', '60 Day Aggregation'),\n",
    "            ('abstract', 'Get a 30 day aggregation')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_9 = dict([('id', 'N_9'),\n",
    "            ('value', 'False'),\n",
    "            ('title', '90 Day Aggregation'),\n",
    "            ('abstract', 'Get a 90 day aggregation')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_12 = dict([('id', 'N_12'),\n",
    "             ('value', 'False'),\n",
    "             ('title', '120 Day Aggregation'),\n",
    "             ('abstract', 'Get a 120 day aggregation')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_15 = dict([('id', 'N_15'),\n",
    "             ('value', 'False'),\n",
    "             ('title', '150 Day Aggregation'),\n",
    "             ('abstract', 'Get a 150 day aggregation')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_18 = dict([('id', 'N_18'),\n",
    "             ('value', 'False'),\n",
    "             ('title', '180 Day Aggregation'),\n",
    "             ('abstract', 'Get a 180 day aggregation')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_27 = dict([('id', 'N_27'),\n",
    "             ('value', 'False'),\n",
    "             ('title', '270 Day Aggregation'),\n",
    "             ('abstract', 'Get a 270 day aggregation')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_36 = dict([('id', 'N_36'),\n",
    "             ('value', 'False'),\n",
    "             ('title', '360 Day Aggregation'),\n",
    "             ('abstract', 'Get a 360 day aggregation')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regionOfInterest = dict([('id', 'regionOfInterest'),\n",
    "                         ('value', 'POLYGON((11.5030755518998 -11.1141633706909,41.0343255518998 -11.1141633706909,41.0343255518998 -34.9763656693858,11.5030755518998 -34.9763656693858,11.5030755518998 -11.1141633706909))'),\n",
    "                         ('title', 'WKT Polygon for the Region of Interest'),\n",
    "                         ('abstract', 'Set the value of WKT Polygon')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nameOfRegion = dict([('id', 'nameOfRegion'),\n",
    "                     ('value', 'Global'),\n",
    "                     ('title', 'Name of Region'),\n",
    "                     ('abstract', 'Name of the region of interest'),\n",
    "                     ('minOccurs', '1')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startdate = dict([('id', 'startdate'),\n",
    "                  ('value', '2016-01-01T00:00Z'),\n",
    "                  ('title', 'Start date'),\n",
    "                  ('abstract', 'Start date')]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enddate = dict([('id', 'enddate'),\n",
    "                ('value', '2016-01-31T23:59Z'),\n",
    "                ('title', 'End date'),\n",
    "                ('abstract', 'End date')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexAgg = dict([('id', 'indexAgg'),\n",
    "                 ('value', 'better-wfp-02-01-02'),\n",
    "                 ('title', 'user'),\n",
    "                 ('abstract', 'user to access catalog'),\n",
    "                 ('minOccurs', '1')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apikeyAgg = dict([('id', 'apikeyAgg'),\n",
    "                  ('value', ''),\n",
    "                  ('title', 'apikey'),\n",
    "                  ('abstract', 'apikey to access catalog'),\n",
    "                  ('minOccurs', '1')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexLTA = dict([('id', 'indexLTA'),\n",
    "                 ('value', 'better-wfp-02-01-03'),\n",
    "                 ('title', 'user'),\n",
    "                 ('abstract', 'user to access LTA catalog'),\n",
    "                 ('minOccurs', '1')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apikeyLTA = dict([('id', 'apikeyLTA'),\n",
    "                  ('value', ''),\n",
    "                  ('title', 'apikey'),\n",
    "                  ('abstract', 'apikey to access LTA catalog'),\n",
    "                  ('minOccurs', '1')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"runtime\">Runtime parameter definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input identifiers**\n",
    "\n",
    "This is the MDOIS stack of products' identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_identifiers = ('BA814DC8750F34CF816D9F575868EEBDB8C8FF43', 'A4A35B1A6722BC3B54A4E2A3AE36CE8697D26BC7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input references**\n",
    "\n",
    "This is the MODIS stack catalogue references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#input_references = ('https://catalog.terradue.com/better-wfp-02-01-02/search?format=atom&uid=BA814DC8750F34CF816D9F575868EEBDB8C8FF43', 'https://catalog.terradue.com/better-wfp-02-01-03/search?format=atom&uid=A4A35B1A6722BC3B54A4E2A3AE36CE8697D26BC7')\n",
    "\n",
    "input_references = ['https://catalog.terradue.com/better-wfp-02-01-02/search?format=atom&uid=8BE72229A47B14B8EEF03385BC883DD1542C5DD9',\n",
    " 'https://catalog.terradue.com/better-wfp-02-01-02/search?format=atom&uid=9F00C1D3DC811CF9DF9E12E5E7342BD3C48160E4',\n",
    " 'https://catalog.terradue.com/better-wfp-02-01-02/search?format=atom&uid=150351E780783792AEFA3D6A7A3CE2506F357D9D',\n",
    " 'https://catalog.terradue.com/better-wfp-02-01-02/search?format=atom&uid=3F03ADB5DF4DACA8D52FD8A5CE240F3814605940',\n",
    " 'https://catalog.terradue.com/better-wfp-02-01-02/search?format=atom&uid=4C0EB6BA565F109E42FC597B8BFBD39278B588DA',\n",
    " 'https://catalog.terradue.com/better-wfp-02-01-02/search?format=atom&uid=CDD6119CC5E300B6E786705D19311F15C69DF336',\n",
    " 'https://catalog.terradue.com/better-wfp-02-01-02/search?format=atom&uid=CD3EAEAD0D74418B41A9E3961CABC7EA6FC3CA4F',\n",
    " 'https://catalog.terradue.com/better-wfp-02-01-02/search?format=atom&uid=433D945250012605A7D18FBAA9D711E4A32B2A0C',\n",
    " 'https://catalog.terradue.com/better-wfp-02-01-02/search?format=atom&uid=DD16ACAD883D7F45BAA95444DC6D415C79E3D587',\n",
    " 'https://catalog.terradue.com/better-wfp-02-01-02/search?format=atom&uid=E86BCE4AB7C6FEACC62E375138C948F58D3EEC3C',\n",
    " 'https://catalog.terradue.com/better-wfp-02-01-02/search?format=atom&uid=0A9114180CC1928E07F0AD8BDA5C8FA53400C288',\n",
    " 'https://catalog.terradue.com/better-wfp-02-01-02/search?format=atom&uid=1D823BE78EDC4DB419B450DBEE1326FF4D7E4194',\n",
    " 'https://catalog.terradue.com/better-wfp-02-01-02/search?format=atom&uid=E437DBEEB2CE6D23165A3868921E342E8EB66806',\n",
    " 'https://catalog.terradue.com/better-wfp-02-01-03/search?format=atom&uid=EB7BC1378DF70E9117F0393FFE47B03045DC30A4',\n",
    " 'https://catalog.terradue.com/better-wfp-02-01-03/search?format=atom&uid=9E20D30EBD2CFD32FFB29EF38B2DE252D756C74D',\n",
    " 'https://catalog.terradue.com/better-wfp-02-01-03/search?format=atom&uid=1E87C98BB9066492134815F7F9174829E5D652EB',\n",
    " 'https://catalog.terradue.com/better-wfp-02-01-03/search?format=atom&uid=831C5B1DF8010833584668C87FAE103BE9585E83',\n",
    " 'https://catalog.terradue.com/better-wfp-02-01-03/search?format=atom&uid=96AE33B045117204E00D24BBE1EB89FFE9C27671',\n",
    " 'https://catalog.terradue.com/better-wfp-02-01-03/search?format=atom&uid=6D5ED7B4934EA47691A030D15B4C16FF7D713B8C',\n",
    " 'https://catalog.terradue.com/better-wfp-02-01-03/search?format=atom&uid=D91A8C33B2B5A84322EF49AF88F3B72EBB79A194',\n",
    " 'https://catalog.terradue.com/better-wfp-02-01-03/search?format=atom&uid=BBBDB9CA245FE1A63F47DA1D601C3D04D904AFB9',\n",
    " 'https://catalog.terradue.com/better-wfp-02-01-03/search?format=atom&uid=33C82638114C570D6973003095AFAFDC96BDF9C5',\n",
    " 'https://catalog.terradue.com/better-wfp-02-01-03/search?format=atom&uid=6D825F8DC18D3589792883F68C708FA79A533937',\n",
    " 'https://catalog.terradue.com/better-wfp-02-01-03/search?format=atom&uid=976A9A405FCCB99779761F65EB44DE546D190641',\n",
    " 'https://catalog.terradue.com/better-wfp-02-01-03/search?format=atom&uid=332D20209FEDE740C985D9C32A47F9632294369D',\n",
    " 'https://catalog.terradue.com/better-wfp-02-01-03/search?format=atom&uid=F9263AF3FBDC0B7F70A86BCF116AA1CEC96B45DA',\n",
    " 'https://catalog.terradue.com/better-wfp-02-01-03/search?format=atom&uid=518C9501277A953D5CF1AB1C8E071661E6A5D4E5']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Data path**\n",
    "\n",
    "This path defines where the data is staged-in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"/workspace/modis/outputs/output_02_03\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aux folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_folder = 'temp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import cioppy\n",
    "\n",
    "import sys\n",
    "import string\n",
    "import numpy as np\n",
    "from osgeo import gdal, ogr, osr\n",
    "from shapely.wkt import loads\n",
    "\n",
    "import pdb\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import datetime\n",
    "\n",
    "ciop = cioppy.Cioppy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_results = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_cfolder(folder):\n",
    "\n",
    "    for the_file in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, the_file)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path): shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print(e) \n",
    "    \n",
    "    \n",
    "# get metadata from catalog\n",
    "def get_input_metadata (input_refs, apikeys):\n",
    "    \n",
    "    # for each product get metadata\n",
    "    Result_Prod = []\n",
    "    \n",
    "    for index,product_ref in enumerate(input_refs):\n",
    "        \n",
    "        for index in apikeys:\n",
    "            if index in product_ref:\n",
    "                cat_index = index\n",
    "                cat_apikey = apikeys[index]\n",
    "        \n",
    "        # since the search is by identifier\n",
    "        Result_Prod.append(ciop.search(end_point = product_ref,params =[],output_fields='self,identifier,startdate,enclosure,startdate,enddate,wkt,title',creds='{}:{}'.format(cat_index,cat_apikey))[0] )\n",
    "    \n",
    "\n",
    "    input_metadata = gpd.GeoDataFrame.from_dict(Result_Prod)\n",
    "\n",
    "    input_metadata['startdate'] = pd.to_datetime(input_metadata['startdate'])\n",
    "    input_metadata['enddate'] = pd.to_datetime(input_metadata['enddate'])\n",
    "    \n",
    "    return input_metadata\n",
    "\n",
    "\n",
    "   \n",
    "    \n",
    "def get_metadata(filepath):\n",
    "\n",
    "    ds = gdal.Open(filepath)\n",
    "    projection = ds.GetProjection()\n",
    "    geotransform = ds.GetGeoTransform()\n",
    "    no_data_value = ds.GetRasterBand(1).GetNoDataValue()\n",
    "    data_type = ds.GetRasterBand(1).DataType\n",
    "    return projection, geotransform, no_data_value, data_type\n",
    "\n",
    "\n",
    "def get_matrix_list(image_list):\n",
    "    mat_list = []\n",
    "    for img in image_list:\n",
    "        dataset = gdal.Open(img)\n",
    "        product_array = dataset.GetRasterBand(1).ReadAsArray()\n",
    "        mat_list.append(product_array)\n",
    "        dataset = None\n",
    "        \n",
    "        print(type(product_array))\n",
    "    return mat_list\n",
    "\n",
    "\n",
    "def calc_anomaly(agg_file, LTA_file):\n",
    "    \n",
    "    if agg_file and LTA_file:\n",
    "        \n",
    "        \n",
    "        agg_and_LTA = get_matrix_list([agg_file, LTA_file])\n",
    "        print('Aggregation and LTA converted to matrices')\n",
    "        \n",
    "        print(agg_and_LTA[0].dtype)\n",
    "        print(agg_and_LTA[1].dtype)\n",
    "        \n",
    "        anomaly_values = (agg_and_LTA[0] * 1.0) - (agg_and_LTA[1] * 1.0)\n",
    "        \n",
    "        print(anomaly_values.dtype)\n",
    "        \n",
    "        projection, geotransform, no_data_value, data_type = get_metadata(agg_file)\n",
    "        \n",
    "        return anomaly_values, projection, geotransform, no_data_value, data_type\n",
    "    \n",
    "    else:\n",
    "        return None, None, None\n",
    "\n",
    "\n",
    "def write_output_image(filepath, output_matrix, image_format, data_format, mask=None, output_projection=None, output_geotransform=None, no_data_value=None):\n",
    "    \n",
    "    driver = gdal.GetDriverByName(image_format)\n",
    "    out_rows = np.size(output_matrix, 0)\n",
    "    out_columns = np.size(output_matrix, 1)\n",
    "    if mask is not None and mask is not 0:\n",
    "        output = driver.Create(filepath, out_columns, out_rows, 2, data_format)\n",
    "        mask_band = output.GetRasterBand(2)\n",
    "        mask_band.WriteArray(mask)\n",
    "        if no_data_value is not None:\n",
    "            output_matrix[mask > 0] = no_data_value\n",
    "    else:\n",
    "        output = driver.Create(filepath, out_columns, out_rows, 1, data_format)\n",
    "    \n",
    "    if output_projection is not None:\n",
    "        output.SetProjection(output_projection)\n",
    "    if output_geotransform is not None:\n",
    "        output.SetGeoTransform(output_geotransform)\n",
    "    \n",
    "    raster_band = output.GetRasterBand(1)\n",
    "    if no_data_value is not None:\n",
    "        raster_band.SetNoDataValue(no_data_value)\n",
    "    raster_band.WriteArray(output_matrix)\n",
    "    gdal.Warp(filepath, output, format=\"GTiff\", outputBoundsSRS='EPSG:4326', xRes=output_geotransform[1], yRes=-output_geotransform[5], targetAlignedPixels=True)\n",
    "\n",
    "    \n",
    "\n",
    "def write_anomaly_output(anomaly, output_folder, product_name, first_date, last_date, lta_start_year, lta_end_year, aggregation, mask_no_value, N_value, regionOfInterest, roi_name, projection, geo_transform, no_data_value):\n",
    "    \n",
    "    filename = os.path.join(output_folder, product_name + '_Anomaly_' + roi_name + '_N' + str(N_value) + '_' + aggregation + '_' + first_date + '_' + last_date + '_LTA' + str(lta_start_year) + '_' + str(lta_end_year) + '.tif')\n",
    "    \n",
    "    write_output_image(filename, anomaly, 'GTiff', gdal.GDT_Float32, mask_no_value, projection, geo_transform, no_data_value)\n",
    "    \n",
    "    return filename\n",
    "\n",
    "\n",
    "\n",
    "def get_formatted_date(date_str):\n",
    "    date = datetime.datetime.strftime(date_str, '%Y-%m-%dT00:00:00Z')\n",
    "    return date\n",
    "\n",
    "\n",
    "def write_properties_file(output_name, first_date, last_date, region_of_interest):\n",
    "    \n",
    "    title = 'Output %s' % output_name\n",
    "    \n",
    "    first_date = get_formatted_date(first_date)\n",
    "    last_date = get_formatted_date(last_date)\n",
    "    \n",
    "    with open(output_name + '.properties', 'wb') as file:\n",
    "        file.write('title=%s\\n' % title)\n",
    "        file.write('date=%s/%s\\n' % (first_date, last_date))\n",
    "        file.write('geometry=%s' % (region_of_interest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(output_folder) > 0:\n",
    "    if not os.path.isdir(output_folder):\n",
    "        os.mkdir(output_folder)\n",
    "\n",
    "if not os.path.isdir(temp_folder):\n",
    "    os.mkdir(temp_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = 'Getting metadata from catalog' \n",
    "ciop.log('INFO', message)\n",
    "\n",
    "# organize indexes and apikeys in a python dictionary\n",
    "apikeys = {indexAgg['value']: apikeyAgg['value'], indexLTA['value']: apikeyLTA['value']}\n",
    "\n",
    "# get input data from catalog\n",
    "input_metadata = get_input_metadata (input_references, apikeys)\n",
    "\n",
    "input_metadata_LTA = input_metadata[input_metadata['title'].str.find('LTA') != -1]\n",
    "input_metadata_Agg = input_metadata[input_metadata['title'].str.find('LTA') == -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(input_metadata_LTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(input_metadata_Agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_lat_idx = {}\n",
    "\n",
    "# N time steps\n",
    "nlist = [N_1['value'], N_3['value'], N_6['value'], N_9['value'], N_12['value'], N_15['value'], N_18['value'], N_27['value'], N_36['value']]\n",
    "nlist = [n == 'True' for n in nlist]\n",
    "nvalues = [1, 3, 6, 9, 12, 15, 18, 27, 36]\n",
    "\n",
    "for bl,nv in zip(nlist, nvalues):\n",
    "    \n",
    "    # only works for selected N time steps\n",
    "    if bl:\n",
    "        \n",
    "        subN_input_metadata_Agg = input_metadata_Agg[input_metadata_Agg['title'].str.contains('_N(?:{})_'.format(nv))]\n",
    "        subN_input_metadata_LTA = input_metadata_LTA[input_metadata_LTA['title'].str.contains('_N(?:{})_'.format(nv))]\n",
    "\n",
    "        for index_agg, row_agg in subN_input_metadata_Agg.iterrows():\n",
    "            #print(row['c1'], row['c2'])\n",
    "            agg_lat_idx[index_agg] = []\n",
    "\n",
    "            sm = pd.to_datetime(row_agg['startdate']).month\n",
    "            sd = pd.to_datetime(row_agg['startdate']).day\n",
    "            em = pd.to_datetime(row_agg['enddate']).month\n",
    "            ed = pd.to_datetime(row_agg['enddate']).day\n",
    "\n",
    "\n",
    "\n",
    "            for index_lta, row_lta in subN_input_metadata_LTA.iterrows():\n",
    "\n",
    "                if sm == pd.to_datetime(row_lta['startdate']).month and sd == pd.to_datetime(row_lta['startdate']).day and em == pd.to_datetime(row_lta['enddate']).month and ed == pd.to_datetime(row_lta['enddate']).day:\n",
    "                    if row_agg['title'].split('_')[3] in row_lta['title']:\n",
    "                        agg_lat_idx[index_agg].append(index_lta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for agg_idx in agg_lat_idx:\n",
    "    print((input_metadata_Agg.loc[agg_idx]['title']) , (input_metadata_LTA.loc[agg_lat_idx[agg_idx][0]]['title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_of_interest = regionOfInterest['value']\n",
    "name_of_region = nameOfRegion['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add something to choose between LTAs list\n",
    "for agg_idx in agg_lat_idx:\n",
    "    #print((input_metadata_Agg.loc[agg_idx]['title']) , (input_metadata_LTA.loc[agg_lat_idx[agg_idx][0]]['title']))\n",
    "    \n",
    "    if len(agg_lat_idx[agg_idx]) < 1:\n",
    "        continue\n",
    "    \n",
    "    sub_input_metadata_Agg = input_metadata_Agg.loc[agg_idx]\n",
    "    sub_input_metadata_LTA = input_metadata_LTA.loc[agg_lat_idx[agg_idx][0]]\n",
    "    \n",
    "    \n",
    "    # get data paths from catalog metadata\n",
    "    filepath_agg = os.path.join(data_path, sub_input_metadata_Agg['enclosure'].split('/')[-1])\n",
    "    filepath_LTA = os.path.join(data_path, sub_input_metadata_LTA['enclosure'].split('/')[-1])\n",
    "    \n",
    "    \n",
    "    print(filepath_agg)\n",
    "    print(filepath_LTA)\n",
    "    \n",
    "    \n",
    "    # get metadata from catalog metadata (Agg and LTA)\n",
    "\n",
    "    # Agg\n",
    "\n",
    "    file_name_elements = os.path.basename(filepath_agg).split('.')[0].split('_')\n",
    "\n",
    "    agg_type = file_name_elements[-3]\n",
    "    \n",
    "    Nn = file_name_elements[-4]\n",
    "    nv = int(Nn.split('N')[-1])\n",
    "\n",
    "    first_date = sub_input_metadata_Agg['startdate'].strftime('%Y-%m-%d')\n",
    "    last_date = sub_input_metadata_Agg['enddate'].strftime('%Y-%m-%d')\n",
    "\n",
    "    print(nv)\n",
    "    print(first_date)\n",
    "    print(last_date)\n",
    "    \n",
    "    \n",
    "    # LTA\n",
    "\n",
    "    file_name_elements = os.path.basename(filepath_LTA).split('.')[0].split('_')\n",
    "\n",
    "    agg_type_LTA = file_name_elements[-5]\n",
    "    Nn_LTA = file_name_elements[-6]\n",
    "\n",
    "\n",
    "    start_year = str(sub_input_metadata_LTA['startdate'].year)\n",
    "    end_year = str(sub_input_metadata_LTA['enddate'].year)\n",
    "\n",
    "    print(start_year)\n",
    "    print(end_year)\n",
    "    \n",
    "      \n",
    "\n",
    "    message = 'Computing Anomaly'\n",
    "    ciop.log('INFO', message)\n",
    "\n",
    "    anomaly_values, projection, geotransform, no_data_value, data_type = calc_anomaly(filepath_agg, filepath_LTA)\n",
    "\n",
    "    message = 'Writing anomaly image'\n",
    "    ciop.log('INFO', message)\n",
    "\n",
    "    filename = write_anomaly_output(anomaly_values, output_folder, 'LST', first_date, last_date, start_year, end_year, agg_type, None, nv, region_of_interest, name_of_region, projection, geotransform, no_data_value)\n",
    "    write_properties_file(filename, datetime.datetime.strptime(first_date, \"%Y-%m-%d\").date(), datetime.datetime.strptime(last_date, \"%Y-%m-%d\").date(), region_of_interest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_results:\n",
    "\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(anomaly_values)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_results:\n",
    "\n",
    "    import rasterio\n",
    "\n",
    "    from rasterio.plot import show\n",
    "\n",
    "    # Load data\n",
    "    raster = filename\n",
    "    data = rasterio.open(raster)\n",
    "\n",
    "    show(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove temporay files and folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_cfolder(temp_folder)\n",
    "\n",
    "os.rmdir(temp_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
